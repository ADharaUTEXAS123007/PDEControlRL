-Relatively long training, but not very convinving results
-Reward increases steadily, relatively low variance

-Fluid creeps slowly out of the initial shape
    => Network too timid to exert large forces
        => Reward increase probably due to the fact that the amount of
                forces created is minimized
-Proximity to goal shape is only considered in the final timestep
    => Network does not get good training samples to understand what to
            do as it seldom reaches the target shape, due to the
            small forces
        
        
-Main takeaways:
    -When only the final proximity is considered, the force penalty must
            not be too large
    -Should try again with much lower force penalty or even adaptive
            penalty that increases during training
